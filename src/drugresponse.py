# -*- coding: utf-8 -*-
"""DrugResponse.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1agDjF2c0ib9NbS0DnWePqFbqB6UKIyp9

**Connect Google Drive**
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""# Pre-Processing

**Download RNA-seq data**
"""

import pandas as pd

# Load the cell line names
cell_line_path = '/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/data/CellLineNames.csv'
df_cell_line_names = pd.read_csv(cell_line_path)

# Load the RNA-seq data
extracted_csv_path = '/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/data/rnaseq_tpm_20220624.csv'
df_sample = pd.read_csv(extracted_csv_path)

# Drop unnecessary rows based on specific values in the first column
rows_to_drop = ['dataset_name', 'data_source', 'gene_id', 'model_name']
df_cleaned = df_sample[~df_sample.iloc[:, 0].isin(rows_to_drop)].copy()

# Transpose the matrix
df_transposed = df_cleaned.transpose()

# Set the first row as headers, then remove that row from the DataFrame
df_transposed.columns = df_transposed.iloc[0]  # Take the first row for the header
df_transposed = df_transposed[1:]              # Take the data below the header row

# Get the set of model IDs from df_cell_line_names
matched_model_ids = set(df_cell_line_names['Model ID'])

# Filter df_transposed to keep only the rows with indices that match model IDs in df_cell_line_names
df_transposed_filtered = df_transposed[df_transposed.index.isin(matched_model_ids)]


# Display the filtered DataFrame and count the number of matches
display(df_transposed_filtered.head())
print(f"Number of matching model_id rows in df_transposed: {len(df_transposed_filtered)}")

"""**RNA-seq Pre-processing using min-max scaling**"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Ensure all data is numeric (without overwriting headers)
df_transposed_filtered_numeric = df_transposed_filtered.apply(pd.to_numeric, errors='coerce')

# Drop any columns with all NaN values
df_transposed_filtered_numeric.dropna(axis=1, how='all', inplace=True)

# Filter out genes with low variability (standard deviation < 0.1)
# Calculate the standard deviation of each gene (column)
std_dev = df_transposed_filtered_numeric.std(axis=0)

# Keep only genes with a standard deviation >= 0.1
df_filtered_high_variability = df_transposed_filtered_numeric.loc[:, std_dev >= 0.1]

# Apply Min-Max Scaling and retain original column names
scaler = MinMaxScaler()
data_scaled = pd.DataFrame(scaler.fit_transform(df_filtered_high_variability),
                           index=df_filtered_high_variability.index,
                           columns=df_filtered_high_variability.columns)

# Display the scaled data
display(data_scaled.head())
print(data_scaled.shape)

"""**Conditional Data Download**"""

import pandas as pd

# Load the cell line names
copy_number_path = '/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/data/cnv_summary_20230303.csv'
df_cnv = pd.read_csv(copy_number_path)


# Load the RNA-seq data
mutation_path = '/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/data/mutations_summary_20230202.csv'
df_mutation = pd.read_csv(mutation_path)

"""**Conditional Information Formatting**"""

from sklearn.preprocessing import MinMaxScaler, OneHotEncoder

# Initialize the scaler and encoder
scaler = MinMaxScaler()
one_hot_encoder = OneHotEncoder(sparse_output=False)

# Drop unnecessary columns in CNV data
df_cnv_cleaned = df_cnv.drop(columns=['model_name', 'symbol', 'source', 'data_type'])
df_mutation_cleaned = df_mutation.drop(columns=['model_name', 'gene_symbol', 'rna_mutation', 'cdna_mutation', 'source'])


# Find the common cell lines across all datasets
rnaseq_cell_lines = set(data_scaled.index)
cnv_cell_lines = set(df_cnv_cleaned['model_id'])
mutation_cell_lines = set(df_mutation_cleaned['model_id'])

common_cell_lines = rnaseq_cell_lines.intersection(cnv_cell_lines).intersection(mutation_cell_lines)

# Filter RNA-seq data
rnaseq_filtered = data_scaled.loc[list(common_cell_lines)]

# Filter each dataset to keep only the common cell lines
rnaseq_filtered = data_scaled.loc[list(common_cell_lines)]
cnv_filtered = df_cnv_cleaned[df_cnv_cleaned['model_id'].isin(common_cell_lines)]
mutation_filtered = df_mutation_cleaned[df_mutation_cleaned['model_id'].isin(common_cell_lines)]

# One-hot encode the categorical 'cn_category' column in CNV data
cnv_category_encoded = one_hot_encoder.fit_transform(cnv_filtered[['cn_category']])
cnv_category_encoded_df = pd.DataFrame(cnv_category_encoded, columns=one_hot_encoder.get_feature_names_out(['cn_category']))
cnv_filtered = pd.concat([cnv_filtered.reset_index(drop=True), cnv_category_encoded_df], axis=1).drop(columns=['cn_category'])

# Scale numeric columns in CNV data (e.g., 'total_copy_number') to [0, 1] range
cnv_filtered[['total_copy_number']] = scaler.fit_transform(cnv_filtered[['total_copy_number']])

# One-hot encode the categorical 'effect' column in Mutation data
mutation_effect_encoded = one_hot_encoder.fit_transform(mutation_filtered[['effect']])
mutation_effect_encoded_df = pd.DataFrame(mutation_effect_encoded, columns=one_hot_encoder.get_feature_names_out(['effect']))
mutation_filtered = pd.concat([mutation_filtered.reset_index(drop=True), mutation_effect_encoded_df], axis=1).drop(columns=['effect'])

# Scale numeric columns in Mutation data (e.g., 'vaf') to [0, 1] range
mutation_filtered[['vaf']] = scaler.fit_transform(mutation_filtered[['vaf']])

# Aggregate CNV and mutation data by 'model_id' to create a single row per cell line
# For CNV, use mean values for total copy number and sum for the one-hot encoded categories per cell line
cnv_aggregated = cnv_filtered.groupby('model_id').agg(
    {'total_copy_number': 'mean', **{col: 'sum' for col in cnv_category_encoded_df.columns}}
)

# For mutation data, use mean values for VAF and sum for one-hot encoded categories per cell line
mutation_aggregated = mutation_filtered.groupby('model_id').agg(
    {'vaf': 'mean', **{col: 'sum' for col in mutation_effect_encoded_df.columns}}
)

# Ensure the indices match for merging
# rnaseq_filtered = rnaseq_filtered.sort_index()
cnv_aggregated = cnv_aggregated.sort_index()
mutation_aggregated = mutation_aggregated.sort_index()

# Concatenate the CNV and mutation data as conditional input
conditional_data = pd.concat([cnv_aggregated, mutation_aggregated], axis=1)
conditional_data = cnv_aggregated

print("Conditional Input:")
display(conditional_data)
print("\nRNA-seq Data:")
display(rnaseq_filtered)

"""# Non Conditional VAE Architecture"""

import tensorflow as tf
from tensorflow.keras import layers

# Encoder
def build_encoder(input_shape):
    inputs = tf.keras.Input(shape=input_shape)
    x = layers.Dense(1024, activation="relu")(inputs)
    x = layers.Dense(512, activation="relu")(x)
    x = layers.Dense(256, activation="relu")(x)
    z_mean = layers.Dense(latent_dim)(x)
    z_log_var = layers.Dense(latent_dim)(x)
    return tf.keras.Model(inputs, [z_mean, z_log_var], name="encoder")

# Sampling Layer remains the same
class Sampling(layers.Layer):
    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = tf.shape(z_mean)[0]
        dim = tf.shape(z_mean)[1]
        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon

# Decoder
def build_decoder(output_shape):
    latent_inputs = tf.keras.Input(shape=(latent_dim,))
    x = layers.Dense(256, activation="relu")(latent_inputs)
    x = layers.Dense(512, activation="relu")(x)
    x = layers.Dense(1024, activation="relu")(x)
    outputs = layers.Dense(output_shape, activation="sigmoid")(x)  # Use sigmoid if data is normalized to [0,1]
    return tf.keras.Model(latent_inputs, outputs, name="decoder")

"""**Build VAE**"""

# Set a scaling factor for KL divergence
beta = 0.01  # Choose a value <1 to reduce KL divergence impact

class VAE(tf.keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.sampling = Sampling()

    def call(self, inputs):
        z_mean, z_log_var = self.encoder(inputs)
        z = self.sampling((z_mean, z_log_var))
        reconstructed = self.decoder(z)

        # Calculate KL divergence loss and scale by beta
        kl_loss = -0.5 * tf.reduce_mean(
            tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)
        )
        self.add_loss(beta * kl_loss)  # Scale the KL divergence term by beta
        return reconstructed

# Define your custom VAE loss function
def vae_loss(inputs, outputs):
    # MSE for reconstruction loss
    reconstruction_loss = tf.reduce_mean(tf.square(inputs - outputs))
    return reconstruction_loss  # The KL divergence is already added as a model loss

"""# VAE Cross Validation"""

import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt
import os

# Assuming rnaseq_filtered is already loaded and indexed by SANGER_MODEL_ID
X = rnaseq_filtered.values  # Convert to numpy for compatibility with KFold
index = rnaseq_filtered.index  # Store the original index

# Define the number of folds for cross-validation
n_splits = 5
kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)

# Define the VAE model dimensions
input_shape = (31337,)  # Update this to match your actual input shape
latent_dim = 45  # Adjust the latent dimension as needed

# Iterate over each fold
for fold, (train_idx, test_idx) in enumerate(kfold.split(X)):
    print(f"Training on fold {fold+1}/{n_splits}")

    # Split the data and keep the indices for alignment
    X_train, X_test = X[train_idx], X[test_idx]
    train_indices, test_indices = index[train_idx], index[test_idx]

    # Build and compile the VAE
    encoder = build_encoder(input_shape)
    decoder = build_decoder(input_shape[0])
    vae = VAE(encoder, decoder)

    learning_rate = 0.001
    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
    vae.compile(optimizer=optimizer, loss=vae_loss)

    # Train the VAE on the training data
    history = vae.fit(X_train, X_train, epochs=200, batch_size=64, verbose=1)

    # Get only the mean latent representations for training and test sets
    train_latent_vectors, _ = encoder.predict(X_train)
    test_latent_vectors, _ = encoder.predict(X_test)

    # Convert latent vectors to DataFrames with original indices
    train_latent_df = pd.DataFrame(train_latent_vectors, index=train_indices)
    test_latent_df = pd.DataFrame(test_latent_vectors, index=test_indices)

    # Define paths for saving CSV files
    train_path = f'/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/output/space/latent_vectors_train_latent=45_fold={fold+1}.csv'
    test_path = f'/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/output/space/latent_vectors_test_latent=45_fold={fold+1}.csv'

    # Ensure directories exist
    os.makedirs(os.path.dirname(train_path), exist_ok=True)
    os.makedirs(os.path.dirname(test_path), exist_ok=True)

    # Save the latent vectors as CSV files with indices
    train_latent_df.to_csv(train_path)
    test_latent_df.to_csv(test_path)

    print(f"Saved latent representations for fold {fold+1}")

"""# Prediction non Conditional

**Sensitivity labels creation binary**
"""

import pandas as pd
import numpy as np
from IPython.display import display

# Load the GDSC data
file_path_GDSC = '/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/data/GDSC1_fitted_dose_response_27Oct23.xlsx'
df_GDSC = pd.read_excel(file_path_GDSC)

# Filter and preprocess GDSC data
df_GDSC_filtered = df_GDSC[['SANGER_MODEL_ID', 'LN_IC50', 'MAX_CONC', 'DRUG_ID', 'DRUG_NAME']].drop_duplicates(
    subset=['SANGER_MODEL_ID', 'DRUG_ID'])

# Normalize LN_IC50 and create sensitivity labels (performed only once)
df_GDSC_filtered['Normalized_IC50'] = df_GDSC_filtered.apply(
    lambda row: np.log(np.exp(row['LN_IC50']) / row['MAX_CONC']) if pd.notnull(row['LN_IC50']) else np.nan, axis=1
)

# Define sensitivity labels by drug based on the 30th percentile
df_GDSC_filtered['Sensitivity_Label'] = df_GDSC_filtered.groupby('DRUG_ID', group_keys=False).apply(
    lambda df: df['Normalized_IC50'].apply(lambda x: 'sensitive' if x <= df['Normalized_IC50'].quantile(0.30) else 'resistant')
)

# Keep only the relevant columns after processing, replacing LN_IC50 with Normalized_IC50
df_GDSC_filtered = df_GDSC_filtered[['SANGER_MODEL_ID', 'DRUG_ID', 'DRUG_NAME', 'Normalized_IC50', 'Sensitivity_Label']]

"""**Sensitivity label creation 3 groups**"""

import pandas as pd
import numpy as np
from IPython.display import display

# Load the GDSC data
file_path_GDSC = '/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/data/GDSC1_fitted_dose_response_27Oct23.xlsx'
df_GDSC = pd.read_excel(file_path_GDSC)

# Filter and preprocess GDSC data
df_GDSC_filtered = df_GDSC[['SANGER_MODEL_ID', 'LN_IC50', 'MAX_CONC', 'DRUG_ID', 'DRUG_NAME']].drop_duplicates(
    subset=['SANGER_MODEL_ID', 'DRUG_ID'])

# Normalize LN_IC50 and create sensitivity labels
df_GDSC_filtered['Normalized_IC50'] = df_GDSC_filtered.apply(
    lambda row: np.log(np.exp(row['LN_IC50']) / row['MAX_CONC']) if pd.notnull(row['LN_IC50']) else np.nan, axis=1
)

# Define sensitivity labels by drug based on percentiles
def assign_sensitivity_label(df):
    lower_bound = df['Normalized_IC50'].quantile(0.30)
    upper_bound = df['Normalized_IC50'].quantile(0.70)
    return df['Normalized_IC50'].apply(
        lambda x: 'sensitive' if x <= lower_bound else 'resistant' if x > upper_bound else 'intermediate'
    )

df_GDSC_filtered['Sensitivity_Label'] = df_GDSC_filtered.groupby('DRUG_ID', group_keys=False).apply(assign_sensitivity_label)

# Keep only the relevant columns after processing
df_GDSC_filtered = df_GDSC_filtered[['SANGER_MODEL_ID', 'DRUG_ID', 'DRUG_NAME', 'Normalized_IC50', 'Sensitivity_Label']]

# Display the resulting dataframe
display(df_GDSC_filtered)

"""**Prediction Task**"""

import torch
from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Helper function to perform Kernel Ridge Regression using Torch
def kernel_ridge_regression(X_train, y_train, X_test, alpha=1.0, gamma=0.1):
    # Compute the RBF kernel
    K_train = torch.exp(-gamma * torch.cdist(X_train, X_train) ** 2)
    K_test = torch.exp(-gamma * torch.cdist(X_test, X_train) ** 2)

    # Compute alpha (ridge) regularized weights
    n = K_train.size(0)
    ridge = alpha * torch.eye(n, device='cuda')
    alpha_weights = torch.linalg.solve(K_train + ridge, y_train)

    # Predict on test data
    y_pred = K_test @ alpha_weights
    return y_pred

# Set paths and parameters
n_splits = 5
drug_roc_data_vae = {}
train_mse_per_fold = []
test_mse_per_fold = []

# Perform K-fold cross-validation
for fold in range(1, n_splits + 1):
    print(f"Processing fold {fold}/{n_splits}")

    # Load train and test latent vectors for this fold
    train_path = f'/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/output/space/latent_vectors_train_latent=30_fold={fold}.csv'
    test_path = f'/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/output/space/latent_vectors_test_latent=30_fold={fold}.csv'

    df_train = pd.read_csv(train_path, index_col='Unnamed: 0')
    df_test = pd.read_csv(test_path, index_col='Unnamed: 0')

    # Filter preprocessed `df_GDSC_filtered` for matching SANGER_MODEL_IDs
    matching_ids = set(df_train.index).union(set(df_test.index))
    df_GDSC_fold = df_GDSC_filtered[df_GDSC_filtered['SANGER_MODEL_ID'].isin(matching_ids)]

    # Merge GDSC data with train and test latent vectors
    df_train_merged = pd.merge(df_train, df_GDSC_fold, left_index=True, right_on='SANGER_MODEL_ID', how='inner')
    df_test_merged = pd.merge(df_test, df_GDSC_fold, left_index=True, right_on='SANGER_MODEL_ID', how='inner')

    # Initialize MSE tracking for this fold
    train_mse_per_drug = []
    test_mse_per_drug = []

    # Loop over each unique drug and collect predictions and labels across folds
    for drug in df_GDSC_fold['DRUG_NAME'].unique():
        print(f"  Processing drug: {drug}")

        # Initialize storage for each drug if not already initialized
        if drug not in drug_roc_data_vae:
            drug_roc_data_vae[drug] = {"y_true": [], "y_pred": []}

        # Filter data for the current drug
        df_train_drug = df_train_merged[df_train_merged['DRUG_NAME'] == drug]
        df_test_drug = df_test_merged[df_test_merged['DRUG_NAME'] == drug]

        # Extract features and target
        X_train = df_train_drug.drop(columns=['SANGER_MODEL_ID', 'DRUG_ID', 'DRUG_NAME', 'Sensitivity_Label', 'Normalized_IC50']).values
        y_train = df_train_drug['Normalized_IC50'].values
        X_test = df_test_drug.drop(columns=['SANGER_MODEL_ID', 'DRUG_ID', 'DRUG_NAME', 'Sensitivity_Label', 'Normalized_IC50']).values
        y_test = df_test_drug['Normalized_IC50'].values

        # Extract sensitivity labels for ROC curve
        y_test_labels = df_test_drug['Sensitivity_Label'].map({'sensitive': 1, 'resistant': 0}).values

        # Standardize features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Convert data to torch tensors and transfer to GPU
        X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32, device='cuda')
        y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device='cuda')
        X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32, device='cuda')

        # Perform Kernel Ridge Regression
        y_test_pred_tensor = kernel_ridge_regression(X_train_tensor, y_train_tensor, X_test_tensor)
        y_test_pred = y_test_pred_tensor.cpu().detach().numpy()

        # Append the predictions and labels for the current drug
        drug_roc_data_vae[drug]["y_true"].extend(y_test_labels)
        drug_roc_data_vae[drug]["y_pred"].extend(y_test_pred)

        # Calculate MSE for training and test sets
        y_train_pred_tensor = kernel_ridge_regression(X_train_tensor, y_train_tensor, X_train_tensor)
        y_train_pred = y_train_pred_tensor.cpu().detach().numpy()
        train_mse = mean_squared_error(y_train, y_train_pred)
        test_mse = mean_squared_error(y_test, y_test_pred)

        train_mse_per_drug.append(train_mse)
        test_mse_per_drug.append(test_mse)

    # Calculate and store average MSE for this fold
    fold_train_mse = np.mean(train_mse_per_drug)
    fold_test_mse = np.mean(test_mse_per_drug)
    train_mse_per_fold.append(fold_train_mse)
    test_mse_per_fold.append(fold_test_mse)

    print(f"Average Train MSE for fold {fold}: {fold_train_mse}")
    print(f"Average Test MSE for fold {fold}: {fold_test_mse}")

# Calculate and print overall average MSE across all folds
average_train_mse = np.mean(train_mse_per_fold)
average_test_mse = np.mean(test_mse_per_fold)

print("\nOverall Average Train MSE:", average_train_mse)
print("Overall Average Test MSE:", average_test_mse)

# Initialize storage for AUC values
auc_values_vae = []  # To collect AUC values for all drugs

# Compute AUC for all drugs in the VAE data
for drug, data in drug_roc_data_vae.items():
    y_true = np.array(data["y_true"])
    y_pred = np.array(data["y_pred"])

    if len(np.unique(y_true)) > 1:  # Ensure both classes are present
        auc = roc_auc_score(y_true, y_pred)
        auc_values_vae.append(auc)  # Collect AUC value

        if auc >= 0.6 or auc <= 0.4:
            fpr, tpr, _ = roc_curve(y_true, y_pred)
            plt.figure(figsize=(8, 6))
            plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {auc:.2f})", color='blue')
            plt.plot([0, 1], [0, 1], linestyle='--', color='gray', alpha=0.7)
            plt.xlabel("False Positive Rate")
            plt.ylabel("True Positive Rate")
            plt.title(f"ROC Curve for {drug}")
            plt.legend()
            plt.grid(alpha=0.3)
            plt.show()

# Calculate and print the average AUC for VAE
average_auc_vae = np.mean(auc_values_vae)
print(f"Average AUC across all drugs (VAE): {average_auc_vae:.4f}")

"""# Conditional VAE"""

import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.losses import mse

class ConditionalVAE(tf.keras.Model):
    def __init__(self, input_dim, cond_dim, latent_dim, beta=1.0):
        super(ConditionalVAE, self).__init__()

        # Define dimensions
        self.input_dim = input_dim
        self.cond_dim = cond_dim
        self.latent_dim = latent_dim
        self.beta = beta  # Scaling factor for KL divergence

        # Encoder layers
        self.encoder_fc1 = layers.Dense(1024, activation='relu')
        self.encoder_fc2 = layers.Dense(512, activation='relu')
        self.encoder_fc3 = layers.Dense(256, activation='relu')

        # Latent space: mean and log-variance layers
        self.fc_mu = layers.Dense(latent_dim)
        self.fc_logvar = layers.Dense(latent_dim)

        # Decoder layers
        self.decoder_fc1 = layers.Dense(256, activation='relu')
        self.decoder_fc2 = layers.Dense(512, activation='relu')
        self.decoder_fc3 = layers.Dense(1024, activation='relu')
        self.decoder_fc4 = layers.Dense(input_dim, activation='sigmoid')  # Use sigmoid if input is in range [0, 1]

        # Add a loss tracker for logging
        self.loss_tracker = tf.keras.metrics.Mean(name="loss")

    def encode(self, x, c):
        # Concatenate input data and condition
        x_cond = layers.concatenate([x, c])

        # Pass through encoder layers
        h = self.encoder_fc1(x_cond)
        h = self.encoder_fc2(h)
        h = self.encoder_fc3(h)

        # Generate mean and log-variance for the latent space
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar

    def reparameterize(self, mu, logvar):
        # Sample from the latent space using reparameterization trick
        std = tf.exp(0.5 * logvar)
        eps = tf.random.normal(shape=tf.shape(std))
        return mu + eps * std

    def decode(self, z, c):
        # Concatenate latent variable and condition
        z_cond = layers.concatenate([z, c])

        # Pass through decoder layers
        h = self.decoder_fc1(z_cond)
        h = self.decoder_fc2(h)
        h = self.decoder_fc3(h)
        recon_x = self.decoder_fc4(h)
        return recon_x

    def call(self, x, c):
        # Encode x to obtain mu and logvar
        mu, logvar = self.encode(x, c)

        # Reparameterize to get latent variable z
        z = self.reparameterize(mu, logvar)

        # Decode z to reconstruct x
        recon_x = self.decode(z, c)

        return recon_x, mu, logvar

    def train_step(self, data):
        x, c = data  # Unpack the tuple

        with tf.GradientTape() as tape:
            # Forward pass
            recon_x, mu, logvar = self(x, c)
            # Compute loss
            loss = self.compute_loss(x, recon_x, mu, logvar)

        # Compute gradients and apply them
        gradients = tape.gradient(loss, self.trainable_variables)
        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))

        # Log the loss
        self.loss_tracker.update_state(loss)

        return {"loss": self.loss_tracker.result()}

    def compute_loss(self, x, recon_x, mu, logvar):
        # Reconstruction loss (e.g., MSE or binary cross-entropy depending on your input data)
        reconstruction_loss = mse(x, recon_x) * x.shape[1]

        # KL divergence
        kl_loss = -0.5 * tf.reduce_sum(1 + logvar - tf.square(mu) - tf.exp(logvar), axis=-1)

        # Total VAE loss with adjustable beta for KL divergence
        total_loss = tf.reduce_mean(reconstruction_loss + self.beta * kl_loss)
        return total_loss

    def get_latent_vectors(self, x, c):
        # Encode and get the latent vectors (mu)
        mu, _ = self.encode(x, c)
        return mu

"""# KFold cVAE Training

**Align the rna data with the conditional data**
"""

import numpy as np
# Sort both DataFrames by their index (SANGER_MODEL_ID)
rnaseq_filtered_sorted = rnaseq_filtered.sort_index()
conditional_data_sorted = conditional_data.sort_index()

# Align RNA-seq and conditional data based on cell line (SANGER_MODEL_ID)
merged_data = pd.merge(
    rnaseq_filtered_sorted, conditional_data_sorted, left_index=True, right_index=True, how="inner"
)

# Separate the merged data back into RNA-seq and conditional data
X = merged_data[rnaseq_filtered.columns].values  # RNA-seq data as numpy array
C = merged_data[conditional_data.columns].values  # Conditional data as numpy array
index = merged_data.index  # Store the original cell line indices

# Confirm alignment
print("RNA-seq data shape:", X.shape)
print("Conditional data shape:", C.shape)
print("Index alignment:", np.array_equal(rnaseq_filtered_sorted.index, conditional_data_sorted.index))

import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt
import os

# Set dimensions for cVAE
input_dim = 31337  # Dimension of RNA-seq data
cond_dim = 6      # Dimension of conditional data
latent_dim = 15   # Latent space dimension
beta = 0.01      # Beta for KL divergence

# Prepare k-fold cross-validation
X = rnaseq_filtered.values  # RNA-seq data as numpy array
C = conditional_data.values  # Conditional data as numpy array
index = rnaseq_filtered.index  # Store original indices

n_splits = 5
kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)

# Iterate over each fold
for fold, (train_idx, test_idx) in enumerate(kfold.split(X)):
    print(f"Training on fold {fold+1}/{n_splits}")

    # Split RNA-seq data and conditional data for this fold
    X_train, X_test = X[train_idx], X[test_idx]
    C_train, C_test = C[train_idx], C[test_idx]
    train_indices, test_indices = index[train_idx], index[test_idx]

    # Instantiate and compile the cVAE for each fold
    cvae = ConditionalVAE(input_dim=input_dim, cond_dim=cond_dim, latent_dim=latent_dim, beta=beta)
    cvae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))

    # Create TensorFlow Dataset with both RNA-seq and conditional data for training
    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, C_train)).batch(64)

    # Train the cVAE and capture the history
    history = cvae.fit(train_dataset, epochs=200, verbose=1)

    # Plot the loss development
    plt.figure()
    plt.plot(history.history['loss'], label='Training Loss')
    plt.title(f'Loss Development for Fold {fold+1}')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.ylim(30, 300)  # Set the y-axis range to focus on 200
    plt.legend()
    plt.show()

    # Extract latent vectors for training and test sets
    train_latent_vectors = cvae.get_latent_vectors(X_train, C_train)
    test_latent_vectors = cvae.get_latent_vectors(X_test, C_test)

    # Convert latent vectors to DataFrames with original indices
    train_latent_df = pd.DataFrame(train_latent_vectors, index=train_indices)
    test_latent_df = pd.DataFrame(test_latent_vectors, index=test_indices)

    # Define paths for saving CSV files
    train_path = f'/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/output/ablation/cnv_latent_vectors_dense_train_latent=50_fold={fold+1}.csv'
    test_path = f'/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/output/ablation/cnv_latent_vectors_dense_test_latent=50_fold={fold+1}.csv'

    # Ensure directories exist
    os.makedirs(os.path.dirname(train_path), exist_ok=True)
    os.makedirs(os.path.dirname(test_path), exist_ok=True)


    # Save the latent vectors as CSV files with indices
    train_latent_df.to_csv(train_path)
    test_latent_df.to_csv(test_path)

    print(f"Saved latent representations and loss plot for fold {fold+1}")

import torch
from sklearn.metrics import (
    mean_squared_error,
    precision_recall_curve,
    average_precision_score,
    roc_auc_score
)
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Helper function to perform Kernel Ridge Regression using Torch
def kernel_ridge_regression(X_train, y_train, X_test, alpha=1.0, gamma=0.1):
    # Compute the RBF kernel
    K_train = torch.exp(-gamma * torch.cdist(X_train, X_train) ** 2)
    K_test = torch.exp(-gamma * torch.cdist(X_test, X_train) ** 2)

    # Compute alpha (ridge) regularized weights
    n = K_train.size(0)
    ridge = alpha * torch.eye(n, device='cuda')
    alpha_weights = torch.linalg.solve(K_train + ridge, y_train)

    # Predict on test data
    y_pred = K_test @ alpha_weights
    return y_pred

# Set paths and parameters
n_splits = 5
drug_metrics_data = {}  # Store metrics (PR and ROC)
train_mse_per_fold = []
test_mse_per_fold = []

# Perform K-fold cross-validation
for fold in range(1, n_splits + 1):
    print(f"Processing fold {fold}/{n_splits}")

    # Load train and test latent vectors for this fold
    train_path = f'/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/output/ablation/latent_vectors_train_latent=15_fold={fold}.csv'
    test_path = f'/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/output/ablation/latent_vectors_test_latent=15_fold={fold}.csv'

    df_train = pd.read_csv(train_path, index_col='Unnamed: 0')
    df_test = pd.read_csv(test_path, index_col='Unnamed: 0')

    # Filter preprocessed `df_GDSC_filtered` for matching SANGER_MODEL_IDs
    matching_ids = set(df_train.index).union(set(df_test.index))
    df_GDSC_fold = df_GDSC_filtered[df_GDSC_filtered['SANGER_MODEL_ID'].isin(matching_ids)]

    # Merge GDSC data with train and test latent vectors
    df_train_merged = pd.merge(df_train, df_GDSC_fold, left_index=True, right_on='SANGER_MODEL_ID', how='inner')
    df_test_merged = pd.merge(df_test, df_GDSC_fold, left_index=True, right_on='SANGER_MODEL_ID', how='inner')

    # Initialize MSE tracking for this fold
    train_mse_per_drug = []
    test_mse_per_drug = []

    # Loop over each unique drug and collect predictions and labels across folds
    for drug in df_GDSC_fold['DRUG_NAME'].unique():
        print(f"  Processing drug: {drug}")

        # Initialize storage for each drug if not already initialized
        if drug not in drug_metrics_data:
            drug_metrics_data[drug] = {"y_true": [], "y_pred": []}

        # Filter data for the current drug
        df_train_drug = df_train_merged[df_train_merged['DRUG_NAME'] == drug]
        df_test_drug = df_test_merged[df_test_merged['DRUG_NAME'] == drug]

        # Extract features and target
        X_train = df_train_drug.drop(columns=['SANGER_MODEL_ID', 'DRUG_ID', 'DRUG_NAME', 'Sensitivity_Label', 'Normalized_IC50']).values
        y_train_labels = df_train_drug['Sensitivity_Label'].map({'sensitive': 1, 'resistant': 0}).values
        X_test = df_test_drug.drop(columns=['SANGER_MODEL_ID', 'DRUG_ID', 'DRUG_NAME', 'Sensitivity_Label', 'Normalized_IC50']).values
        y_test_labels = df_test_drug['Sensitivity_Label'].map({'sensitive': 1, 'resistant': 0}).values

        # Standardize features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Convert data to torch tensors and transfer to GPU
        X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32, device='cuda')
        y_train_labels_tensor = torch.tensor(y_train_labels, dtype=torch.float32, device='cuda')
        X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32, device='cuda')

        # Perform Kernel Ridge Regression
        y_test_pred_tensor = kernel_ridge_regression(X_train_tensor, y_train_labels_tensor, X_test_tensor)
        y_test_pred = y_test_pred_tensor.cpu().detach().numpy()

        # Append the predictions and labels for the current drug
        drug_metrics_data[drug]["y_true"].extend(y_test_labels)
        drug_metrics_data[drug]["y_pred"].extend(y_test_pred)

        # Calculate MSE for training and test sets
        y_train_pred_tensor = kernel_ridge_regression(X_train_tensor, y_train_labels_tensor, X_train_tensor)
        y_train_pred = y_train_pred_tensor.cpu().detach().numpy()
        train_mse = mean_squared_error(y_train_labels, y_train_pred)
        test_mse = mean_squared_error(y_test_labels, y_test_pred)

        train_mse_per_drug.append(train_mse)
        test_mse_per_drug.append(test_mse)

    # Calculate and store average MSE for this fold
    fold_train_mse = np.mean(train_mse_per_drug)
    fold_test_mse = np.mean(test_mse_per_drug)
    train_mse_per_fold.append(fold_train_mse)
    test_mse_per_fold.append(fold_test_mse)

    print(f"Average Train MSE for fold {fold}: {fold_train_mse}")
    print(f"Average Test MSE for fold {fold}: {fold_test_mse}")

# Calculate and print overall average MSE across all folds
average_train_mse = np.mean(train_mse_per_fold)
average_test_mse = np.mean(test_mse_per_fold)

print("\nOverall Average Train MSE:", average_train_mse)
print("Overall Average Test MSE:", average_test_mse)

# Calculate PR and ROC metrics
aupr_values = []
auroc_values = []

for drug, data in drug_metrics_data.items():
    y_true = np.array(data["y_true"])
    y_pred = np.array(data["y_pred"])

    if len(np.unique(y_true)) > 1:  # Ensure both classes are present
        # Calculate PR metrics
        average_precision = average_precision_score(y_true, y_pred)
        aupr_values.append(average_precision)

        # Calculate ROC AUC
        roc_auc = roc_auc_score(y_true, y_pred)
        auroc_values.append(roc_auc)

# Calculate averages and ranges for AUROC and AUPR
avg_aupr = np.mean(aupr_values)
avg_auroc = np.mean(auroc_values)
aupr_range = (max(aupr_values) - min(aupr_values)) / avg_aupr * 100
auroc_range = (max(auroc_values) - min(auroc_values)) / avg_auroc * 100

print(f"\nAverage AUPR: {avg_aupr:.4f} ± {aupr_range:.2f}%")
print(f"Average AUROC: {avg_auroc:.4f} ± {auroc_range:.2f}%")

# Save PR and ROC metrics
np.save('drug_metrics_data.npy', drug_metrics_data)

"""# Conditional Prediction Task

**Binary classification**
"""

import torch
from sklearn.metrics import mean_squared_error, precision_recall_curve, average_precision_score, roc_auc_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from imblearn.over_sampling import SMOTE

# Helper function to perform Kernel Ridge Regression using Torch
def conditional_kernel_ridge_regression(X_train_cond, y_train_cond, X_test_cond, alpha=1.0, gamma=0.1):
    # Compute the RBF kernel
    K_train_cond = torch.exp(-gamma * torch.cdist(X_train_cond, X_train_cond) ** 2)
    K_test_cond = torch.exp(-gamma * torch.cdist(X_test_cond, X_train_cond) ** 2)

    # Compute alpha (ridge) regularized weights
    n = K_train_cond.size(0)
    ridge = alpha * torch.eye(n, device='cuda')
    alpha_weights_cond = torch.linalg.solve(K_train_cond + ridge, y_train_cond)

    # Predict on test data
    y_pred_cond = K_test_cond @ alpha_weights_cond
    return y_pred_cond

# Set paths and parameters
n_splits = 5
drug_pr_data = {}
smote = SMOTE(random_state=42)  # Initialize SMOTE
average_precision_values_cvae = []
roc_auc_values_cvae = []

# Perform K-fold cross-validation
for fold in range(1, n_splits + 1):
    print(f"Processing fold {fold}/{n_splits}")

    # Load train and test latent vectors for this fold (conditional VAE)
    train_cond_path = f'/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/output/space/conditional_latent_vectors_train_latent=15_fold={fold}.csv'
    test_cond_path = f'/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/output/space/conditional_latent_vectors_test_latent=15_fold={fold}.csv'

    df_train_cond = pd.read_csv(train_cond_path, index_col='Unnamed: 0')
    df_test_cond = pd.read_csv(test_cond_path, index_col='Unnamed: 0')

    # Filter preprocessed `df_GDSC_filtered` for matching SANGER_MODEL_IDs
    matching_cond_ids = set(df_train_cond.index).union(set(df_test_cond.index))
    df_GDSC_cond_fold = df_GDSC_filtered[df_GDSC_filtered['SANGER_MODEL_ID'].isin(matching_cond_ids)]

    # Merge GDSC data with train and test latent vectors
    df_train_cond_merged = pd.merge(df_train_cond, df_GDSC_cond_fold, left_index=True, right_on='SANGER_MODEL_ID', how='inner')
    df_test_cond_merged = pd.merge(df_test_cond, df_GDSC_cond_fold, left_index=True, right_on='SANGER_MODEL_ID', how='inner')

    # Loop over each unique drug and collect predictions and labels across folds
    for drug in df_GDSC_cond_fold['DRUG_NAME'].unique():
        print(f"  Processing drug: {drug}")

        # Initialize storage for each drug if not already initialized
        if drug not in drug_pr_data:
            drug_pr_data[drug] = {"y_true": [], "y_pred": []}

        # Filter data for the current drug
        df_train_drug_cond = df_train_cond_merged[df_train_cond_merged['DRUG_NAME'] == drug]
        df_test_drug_cond = df_test_cond_merged[df_test_cond_merged['DRUG_NAME'] == drug]

        # Extract features and target
        X_train_cond = df_train_drug_cond.drop(columns=['SANGER_MODEL_ID', 'DRUG_ID', 'DRUG_NAME', 'Sensitivity_Label', 'Normalized_IC50']).values
        y_train_labels = df_train_drug_cond['Sensitivity_Label'].map({'sensitive': 1, 'resistant': 0}).values
        X_test_cond = df_test_drug_cond.drop(columns=['SANGER_MODEL_ID', 'DRUG_ID', 'DRUG_NAME', 'Sensitivity_Label', 'Normalized_IC50']).values
        y_test_labels = df_test_drug_cond['Sensitivity_Label'].map({'sensitive': 1, 'resistant': 0}).values

        # Apply SMOTE for balancing
        X_train_cond_balanced, y_train_labels_balanced = smote.fit_resample(X_train_cond, y_train_labels)

        # Standardize features
        scaler_cond = StandardScaler()
        X_train_cond_scaled = scaler_cond.fit_transform(X_train_cond_balanced)
        X_test_cond_scaled = scaler_cond.transform(X_test_cond)

        # Convert data to torch tensors and transfer to GPU
        X_train_cond_tensor = torch.tensor(X_train_cond_scaled, dtype=torch.float32, device='cuda')
        y_train_labels_tensor = torch.tensor(y_train_labels_balanced, dtype=torch.float32, device='cuda')
        X_test_cond_tensor = torch.tensor(X_test_cond_scaled, dtype=torch.float32, device='cuda')

        # Perform Kernel Ridge Regression
        y_test_pred_cond_tensor = conditional_kernel_ridge_regression(X_train_cond_tensor, y_train_labels_tensor, X_test_cond_tensor)
        y_test_pred_cond = y_test_pred_cond_tensor.cpu().detach().numpy()

        # Append the predictions and labels for the current drug
        drug_pr_data[drug]["y_true"].extend(y_test_labels)
        drug_pr_data[drug]["y_pred"].extend(y_test_pred_cond)

        # Calculate precision-recall data and AUPR
        precision, recall, _ = precision_recall_curve(y_test_labels, y_test_pred_cond)
        ap_score = average_precision_score(y_test_labels, y_test_pred_cond)
        average_precision_values_cvae.append(ap_score)

        # Calculate AUROC
        if len(np.unique(y_test_labels)) > 1:  # Ensure both classes are present
            roc_auc = roc_auc_score(y_test_labels, y_test_pred_cond)
            roc_auc_values_cvae.append(roc_auc)

        # Save precision and recall for plotting
        drug_pr_data[drug]["precision"] = precision
        drug_pr_data[drug]["recall"] = recall
        drug_pr_data[drug]["average_precision"] = ap_score

# Calculate average and range for AUPR and AUROC
avg_aupr = np.mean(average_precision_values_cvae)
avg_auroc = np.mean(roc_auc_values_cvae)
aupr_range = (max(average_precision_values_cvae) - min(average_precision_values_cvae)) / avg_aupr * 100
auroc_range = (max(roc_auc_values_cvae) - min(roc_auc_values_cvae)) / avg_auroc * 100

print(f"\nAverage AUPR: {avg_aupr:.4f} ± {aupr_range:.2f}%")
print(f"Average AUROC: {avg_auroc:.4f} ± {auroc_range:.2f}%")

# # Load saved VAE PR data
# drug_pr_data_vae = np.load('drug_pr_data_vae.npy', allow_pickle=True).item()

# # Sort drugs by AUPR
# pr_scores_cvae = sorted([(drug, data["average_precision"]) for drug, data in drug_pr_data.items()], key=lambda x: x[1], reverse=True)

# # Plot top 3 PR curves
# for i, (drug, ap_cvae) in enumerate(pr_scores_cvae[:3]):
#     print(f"Plotting PR curve for drug: {drug} (AP cVAE: {ap_cvae:.4f})")

#     # cVAE data
#     precision_cvae = drug_pr_data[drug]["precision"]
#     recall_cvae = drug_pr_data[drug]["recall"]

#     # VAE data
#     if drug in drug_pr_data_vae:
#         precision_vae = drug_pr_data_vae[drug]["precision"]
#         recall_vae = drug_pr_data_vae[drug]["recall"]
#         ap_vae = drug_pr_data_vae[drug]["average_precision"]
#     else:
#         print(f"No VAE data found for drug: {drug}")
#         continue

#     # Plot PR curves
#     plt.figure(figsize=(8, 6))
#     plt.plot(recall_cvae, precision_cvae, label=f"cVAE PR (AP = {ap_cvae:.4f})", color='blue')
#     plt.plot(recall_vae, precision_vae, label=f"VAE PR (AP = {ap_vae:.4f})", color='red')
#     plt.xlabel("Recall")
#     plt.ylabel("Precision")
#     plt.title(f"Precision-Recall Curve for {drug}")
#     plt.legend()
#     plt.grid(alpha=0.3)
#     plt.show()

"""**Three Group classification**"""

import torch
from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score, roc_curve
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Helper function to perform Kernel Ridge Regression using Torch
def conditional_kernel_ridge_regression(X_train_cond, y_train_cond, X_test_cond, alpha=1.0, gamma=0.1):
    # Compute the RBF kernel
    K_train_cond = torch.exp(-gamma * torch.cdist(X_train_cond, X_train_cond) ** 2)
    K_test_cond = torch.exp(-gamma * torch.cdist(X_test_cond, X_train_cond) ** 2)

    # Compute alpha (ridge) regularized weights
    n = K_train_cond.size(0)
    ridge = alpha * torch.eye(n, device='cuda')
    alpha_weights_cond = torch.linalg.solve(K_train_cond + ridge, y_train_cond)

    # Predict on test data
    y_pred_cond = K_test_cond @ alpha_weights_cond
    return y_pred_cond

# Set paths and parameters
n_splits = 5
drug_pr_data = {}
average_precision_values_cvae = []
roc_auc_values_cvae = []
train_roc_auc_values = []

# Perform K-fold cross-validation
for fold in range(1, n_splits + 1):
    print(f"Processing fold {fold}/{n_splits}")

    # Load train and test latent vectors for this fold (conditional VAE)
    train_cond_path = f'/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/output/ablation/cnv_mutation_latent_vectors_train_latent=15_fold={fold}.csv'
    test_cond_path = f'/content/drive/MyDrive/Colab Notebooks/ECSE 556/FinalProject/output/ablation/cnv_mutation_latent_vectors_test_latent=15_fold={fold}.csv'

    df_train_cond = pd.read_csv(train_cond_path, index_col='Unnamed: 0')
    df_test_cond = pd.read_csv(test_cond_path, index_col='Unnamed: 0')

    # Filter preprocessed `df_GDSC_filtered` for matching SANGER_MODEL_IDs
    matching_cond_ids = set(df_train_cond.index).union(set(df_test_cond.index))
    df_GDSC_cond_fold = df_GDSC_filtered[df_GDSC_filtered['SANGER_MODEL_ID'].isin(matching_cond_ids)]

    # Merge GDSC data with train and test latent vectors
    df_train_cond_merged = pd.merge(df_train_cond, df_GDSC_cond_fold, left_index=True, right_on='SANGER_MODEL_ID', how='inner')
    df_test_cond_merged = pd.merge(df_test_cond, df_GDSC_cond_fold, left_index=True, right_on='SANGER_MODEL_ID', how='inner')

    # Loop over each unique drug and collect predictions and labels across folds
    for drug in df_GDSC_cond_fold['DRUG_NAME'].unique():
        print(f"  Processing drug: {drug}")

        # Initialize storage for each drug if not already initialized
        if drug not in drug_pr_data:
            drug_pr_data[drug] = {"y_true": [], "y_pred": [], "train_auc": []}

        # Filter data for the current drug
        df_train_drug_cond = df_train_cond_merged[df_train_cond_merged['DRUG_NAME'] == drug]
        df_test_drug_cond = df_test_cond_merged[df_test_cond_merged['DRUG_NAME'] == drug]

        # Extract features and target (binary labels: sensitive vs. others)
        X_train_cond = df_train_drug_cond.drop(columns=['SANGER_MODEL_ID', 'DRUG_ID', 'DRUG_NAME', 'Sensitivity_Label', 'Normalized_IC50']).values
        y_train_labels = (df_train_drug_cond['Sensitivity_Label'] == 'sensitive').astype(int).values
        X_test_cond = df_test_drug_cond.drop(columns=['SANGER_MODEL_ID', 'DRUG_ID', 'DRUG_NAME', 'Sensitivity_Label', 'Normalized_IC50']).values
        y_test_labels = (df_test_drug_cond['Sensitivity_Label'] == 'sensitive').astype(int).values

        # Standardize features
        scaler_cond = StandardScaler()
        X_train_cond_scaled = scaler_cond.fit_transform(X_train_cond)
        X_test_cond_scaled = scaler_cond.transform(X_test_cond)

        # Convert data to torch tensors and transfer to GPU
        X_train_cond_tensor = torch.tensor(X_train_cond_scaled, dtype=torch.float32, device='cuda')
        y_train_labels_tensor = torch.tensor(y_train_labels, dtype=torch.float32, device='cuda')
        X_test_cond_tensor = torch.tensor(X_test_cond_scaled, dtype=torch.float32, device='cuda')

        # Perform Kernel Ridge Regression
        y_train_pred_cond_tensor = conditional_kernel_ridge_regression(X_train_cond_tensor, y_train_labels_tensor, X_train_cond_tensor)
        y_train_pred_cond = y_train_pred_cond_tensor.cpu().detach().numpy()

        y_test_pred_cond_tensor = conditional_kernel_ridge_regression(X_train_cond_tensor, y_train_labels_tensor, X_test_cond_tensor)
        y_test_pred_cond = y_test_pred_cond_tensor.cpu().detach().numpy()

        # Calculate train AUROC
        if len(np.unique(y_train_labels)) > 1:
            train_roc_auc = roc_auc_score(y_train_labels, y_train_pred_cond)
            train_roc_auc_values.append(train_roc_auc)

        # Append the predictions and labels for the current drug
        drug_pr_data[drug]["y_true"].extend(y_test_labels)
        drug_pr_data[drug]["y_pred"].extend(y_test_pred_cond)

        # Calculate precision-recall data and AUPR
        precision, recall, _ = precision_recall_curve(y_test_labels, y_test_pred_cond)
        ap_score = average_precision_score(y_test_labels, y_test_pred_cond)
        average_precision_values_cvae.append(ap_score)

        # Calculate AUROC
        if len(np.unique(y_test_labels)) > 1:  # Ensure both classes are present
            roc_auc = roc_auc_score(y_test_labels, y_test_pred_cond)
            roc_auc_values_cvae.append(roc_auc)

        # Save precision, recall, and ROC data
        drug_pr_data[drug]["precision"] = precision
        drug_pr_data[drug]["recall"] = recall
        drug_pr_data[drug]["fpr"], drug_pr_data[drug]["tpr"], _ = roc_curve(y_test_labels, y_test_pred_cond)
        drug_pr_data[drug]["average_precision"] = ap_score
        drug_pr_data[drug]["roc_auc"] = roc_auc

# Calculate averages
avg_train_roc_auc = np.mean(train_roc_auc_values)
avg_test_roc_auc = np.mean(roc_auc_values_cvae)
avg_test_aupr = np.mean(average_precision_values_cvae)

print(f"\nAverage Training AUROC: {avg_train_roc_auc:.4f}")
print(f"Average Test AUROC: {avg_test_roc_auc:.4f}")
print(f"Average Test AUPR: {avg_test_aupr:.4f}")

# Plot PR curves for the top 3 drugs
pr_scores_cvae = sorted([(drug, data["average_precision"]) for drug, data in drug_pr_data.items()], key=lambda x: x[1], reverse=True)
for i, (drug, ap_cvae) in enumerate(pr_scores_cvae[:3]):
    print(f"Plotting PR curve for drug: {drug} (AP cVAE: {ap_cvae:.4f})")
    precision = drug_pr_data[drug]["precision"]
    recall = drug_pr_data[drug]["recall"]
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, label=f"cVAE PR (AP = {ap_cvae:.4f})", color='blue')
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title(f"Precision-Recall Curve for {drug} (Sensitive Class)")
    plt.legend()
    plt.grid(alpha=0.3)
    plt.show()

# Plot ROC curves for the top 3 drugs
roc_scores_cvae = sorted([(drug, data["roc_auc"]) for drug, data in drug_pr_data.items()], key=lambda x: x[1], reverse=True)
for i, (drug, roc_auc) in enumerate(roc_scores_cvae[:3]):
    print(f"Plotting ROC curve for drug: {drug} (AUROC cVAE: {roc_auc:.4f})")
    fpr = drug_pr_data[drug]["fpr"]
    tpr = drug_pr_data[drug]["tpr"]
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, label=f"cVAE ROC (AUROC = {roc_auc:.4f})", color='green')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(f"ROC Curve for {drug} (Sensitive Class)")
    plt.legend()
    plt.grid(alpha=0.3)
    plt.show()

'''
Latent = 50
VAE:
Overall Average Train MSE: 0.20977259783460994
Overall Average Test MSE: 0.2105256290939737
cVAE:
cVAE:
Overall Average Train MSE: 0.0849
Overall Average Test MSE: 0.2297
Average AUROC across all drugs: 0.6152

Latent = 45
VAE:
Overall Average Train MSE: 0.2097835142050402
Overall Average Test MSE: 0.21051312309599926
cVAE:
Overall Average Train MSE: 0.0896
Overall Average Test MSE: 0.2293
Average AUROC across all drugs: 0.6277

Latent = 40
VAE:
Overall Average Train MSE: 0.2095835142050402
Overall Average Test MSE: 0.21054313309599926
cVAE:
Overall Average Train MSE: 0.1031
Overall Average Test MSE: 0.2279
Average AUROC across all drugs: 0.6288

Latent = 35
VAE:
Overall Average Train MSE: 0.2096199586898952
Overall Average Test MSE: 0.21056787911100608
cVAE:
Overall Average Train MSE: 0.0994
Overall Average Test MSE: 0.2279
Average AUROC across all drugs: 0.6366

Latent = 30
VAE:
Overall Average Train MSE: 0.16107340106722962
Overall Average Test MSE: 0.244004643318697
cVAE:
Overall Average Train MSE: 0.1181
Overall Average Test MSE: 0.2281
Average AUROC across all drugs: 0.6410

Latent = 25
VAE:
Overall Average Train MSE: 0.1364853605594475
Overall Average Test MSE: 0.26106174112275365
cVAE:
Overall Average Train MSE: 0.1269
Overall Average Test MSE: 0.2274
Average AUROC across all drugs: 0.6437

Latent = 20
VAE:
Overall Average Train MSE: 0.10328345456503411
Overall Average Test MSE: 0.2935430407814609
cVAE:
Overall Average Train MSE: 0.1421
Overall Average Test MSE: 0.2263
Average AUROC across all drugs: 0.6474

'''
import matplotlib.pyplot as plt

# Data
latent_dims = [50, 45, 40, 35, 30, 25, 20]
vae_test_mse = [0.2105, 0.2105, 0.2105, 0.2106, 0.2440, 0.2611, 0.2935]
cvae_test_mse = [0.2297, 0.2293, 0.2279, 0.2279, 0.2281, 0.2274, 0.2263]

# Plot
plt.figure(figsize=(8, 6))
plt.plot(latent_dims, vae_test_mse, marker='o', label='VAE Test MSE', color='blue')
plt.plot(latent_dims, cvae_test_mse, marker='s', label='cVAE Test MSE', color='green')

# Formatting
plt.xlabel("Latent Dimensions", fontsize=12)
plt.ylabel("Overall Average Test MSE", fontsize=12)
plt.title("Overall Test MSE vs Latent Dimensions", fontsize=14)
plt.legend(fontsize=12)
plt.grid(alpha=0.3)
plt.gca().invert_xaxis()  # To show higher latent dimensions on the left
plt.tight_layout()

# Show plot
plt.show()
